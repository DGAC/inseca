#!/usr/bin/python3

# This file is part of INSECA.
#
#    Copyright (C) 2020-2024 INSECA authors
#
#    INSECA is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    INSECA is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with INSECA.  If not, see <https://www.gnu.org/licenses/>

import os
import sys
import uuid
import json
import shlex
import datetime
import tempfile
import tarfile
import shutil
import argparse
import gc

prog_path=os.path.realpath(__file__)
prog_dir=os.path.dirname(prog_path)
sys.path+=[prog_dir, prog_dir+"/../lib"]

import CryptoGen as cgen
import CryptoX509 as x509
import CryptoPass
import Utils as util
import Configurations as confs
import Sync
import Device
import LiveBuilder
import ValueHolder
import Installer
import Live
import Borg
import AppendedData as adata

# Gettext stuff
import gettext
gettext.bindtextdomain("inseca", prog_dir+"/../locales")
gettext.textdomain("inseca")
_ = gettext.gettext
_indent="  "

def _get_single_useable_device():
    devices=util.get_disks()
    dev=None
    for devfile in devices:
        devdata=devices[devfile]
        if devdata["useable"] and not devdata["internal-disk"]:
            if dev:
                raise Exception("More than one device is plugged in the system")
            dev=devfile
    if dev:
        print("Using %s device"%dev)
        return dev
    raise Exception("No suitable plugged device found")


parser=argparse.ArgumentParser()
parser.add_argument("--root", help=_("Specify the equivalent of INSECA_ROOT"))
parser.add_argument("--components-dir", help=_("Specify the equivalent of INSECA_EXTRA_COMPONENTS"))
parser.add_argument("--http-proxy", help=_("Force usage of a specific HTTP/HTTPS proxy (e.g. 'http://my.proxy.local:8080'), use 'none' for direct connections"))
parser.add_argument("--repos-dir", help=_("Specify the equivalent of INSECA_DEFAULT_REPOS_DIR"))
parser.add_argument("--cache-dir", help=_("Specify the equivalent of INSECA_CACHE_DIR"))
parser.add_argument("-v", "--verbose", help=_("Display more information"), action="store_true")

subparsers=parser.add_subparsers(help=_("Allowed commands"), dest="cmde")

sparser=subparsers.add_parser("init", help=_("Initialize a new INSECA global configuration structure"))
sparser=subparsers.add_parser("status", help=_("Display the global status"))

sparser=subparsers.add_parser("configs", help=_("List all the configurations of the specific type"))
# TRANSLATORS: leave the build | install | format | domain | userdata keywords as-is
sparser.add_argument("type", help=_("Config type: build | install | format | domain | userdata"))

sparser=subparsers.add_parser("config-infos", help=_("Show information about a specific configuration"))
sparser.add_argument("config", help=_("Configuration ID"))

sparser=subparsers.add_parser("config-create", help=_("Create a new configuration"))
sparser.add_argument("type", help=_("Config type: admin-build | build | install | format | domain | userdata"))
sparser.add_argument("--build", help=_("Referenced Build ID if config type is 'install' (ignored otherwise)"))
sparser.add_argument("description", help=_("Configuration's description"))

sparser=subparsers.add_parser("config-clone", help=_("Clone a configuration"))
sparser.add_argument("config", help=_("ID of the configuration to clone"))
sparser.add_argument("--other-root", help=_("Path to another INSECA global configuration"))
sparser.add_argument("description", help=_("Cloned configuration's description"))

sparser=subparsers.add_parser("config-publish", help=_("Publish a configuration's contents to its specified repository"))
sparser.add_argument("config", nargs=argparse.REMAINDER, help=_("Configuration(s) ID(s), or empty to specify all the configurations"))

sparser=subparsers.add_parser("config-remove", help=_("Remove a configuration and its associated repository"))
sparser.add_argument("config", nargs=argparse.REMAINDER, help=_("Configuration(s) ID(s)"))
sparser.add_argument("--confirm", help=_("Don't ask for any confirmation"), action="store_true")

sparser=subparsers.add_parser("build", help=_("Build a live Linux"))
sparser.add_argument("build", nargs=argparse.REMAINDER, help=_("Build configuration ID(s)"))
sparser.add_argument("-p", "--publish", help=_("Automatically publish the build (if the build configuration has defined a repository)"), action="store_true")
sparser.add_argument("-n", "--dry", help=_("Don't actually build the live Linux, only prepare the files"), action="store_true")

sparser=subparsers.add_parser("repo-ls", help=_("List all contents of the specified repository"))
sparser.add_argument("repo", help=_("Repository ID"))
sparser.add_argument("--archive", help=_("Archive ID, to list files in that archive"))

sparser=subparsers.add_parser("repo-prune", help=_("Remove all obsolete archives in the repositories (or specified repository)"))
sparser.add_argument("-e", "--empty", help=_("Remove all the repo's archives"), action="store_true")
sparser.add_argument("--confirm", help=_("Don't ask for any confirmation"), action="store_true")
sparser.add_argument("repos", nargs=argparse.REMAINDER, help=_("Repository or repositories ID(s)"))

sparser=subparsers.add_parser("userdata-import", help=_("Import data (replace any existing) in a USERDATA repository"))
sparser.add_argument("repo", help=_("Repository ID"))
sparser.add_argument("path", help=_("Directory containing the files to add"))

sparser=subparsers.add_parser("userdata-add", help=_("Add files(s) in a USERDATA repository"))
sparser.add_argument("repo", help=_("Repository ID"))
sparser.add_argument("files", nargs=argparse.REMAINDER, help=_("Files to add"))

sparser=subparsers.add_parser("userdata-del", help=_("Remove files(s) from a USERDATA repository"))
sparser.add_argument("repo", help=_("Repository ID"))
sparser.add_argument("files", nargs=argparse.REMAINDER, help=_("Files to delete"))

sparser=subparsers.add_parser("sync-push", help=_("Upload the master configuration (or only some repositories) to the specified target storage"))
sparser.add_argument("storage", help=_("Storage target"))
sparser.add_argument("repos", nargs=argparse.REMAINDER, help=_("Repository or repositories ID(s)"))

sparser=subparsers.add_parser("sync-pull", help=_("Download the whole configuration from the specified target storage"))
sparser.add_argument("storage", help=_("Storage target"))

sparser=subparsers.add_parser("gen-admin-iso", help=_("Generate an admin 'iso' image from an admin build and domain(s) configuration(s)"))
sparser.add_argument("build", help=_("Build configuration (must already have been built); pass '-' to generate debug file only"))
sparser.add_argument("domains", nargs=argparse.REMAINDER, help=_("Domain(s) configuration(s) which will be available in the admin environment"))

sparser=subparsers.add_parser("gen-params", help=_("Generate a template of the parameters required to create an INSECA installation or format a device"))
sparser.add_argument("config", help=_("Install/format configuration"))

sparser=subparsers.add_parser("gen-keypair", help=_("Generate an RSA keys pair"))
sparser.add_argument("prefix", help=_("Base name for the generated key files: <prefix>.pub and <prefix>.priv"))

sparser=subparsers.add_parser("devices", help=_("List all mass storage devices in the system"))

sparser=subparsers.add_parser("dev-install", help=_("Create an INSECA installation"))
sparser.add_argument("config", help=_("Install (for workstation install) or build (for simple live Linux) configuration to use"))
sparser.add_argument("target", help=_("Device or VM image file to install to"))
sparser.add_argument("--params-file", help=_("File containing the parameters for the installation (for install configurations)"))
sparser.add_argument("--vm-size", type=int, default=64, help=_("Size of the VM image file in Gb (if target is a VM image file)"))
sparser.add_argument("--archive", help=_("Specific archive ID to get the live Linux image (instead of the last available)"))

sparser=subparsers.add_parser("dev-update-linux", help=_("Update the live Linux of an INSECA installation"))
sparser.add_argument("target", nargs='?', default=None, help=_("Device or VM image file to update"))
sparser.add_argument("--archive", help=_("Specific archive ID to get the live Linux image (instead of the last available)"))

sparser=subparsers.add_parser("dev-format", help=_("Format a storage device using a format configuration"))
sparser.add_argument("format", metavar="format", help=_("Format configuration to use"))
sparser.add_argument("params_file", metavar="params-file", help=_("File containing the parameters for the format"))
sparser.add_argument("target", help=_("Device file to install to"))

sparser=subparsers.add_parser("dev-ident", help=_("Identifies an INSECA device"))
sparser.add_argument("devfile", nargs='?', default=None, help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("--protected", help=_("Also get the protected (encrypted) information"), action="store_true")
sparser.add_argument("--decrypt_key", metavar="decrypt-key", help=_("Force a specific decryption key to get the protected data"))

sparser=subparsers.add_parser("dev-wipe", help=_("Remove everything on a device"))
sparser.add_argument("devfile", help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("--confirm", help=_("Confirm the removal without any confirmation asked"), action="store_true")
sparser.add_argument("--metadata-only", help=_("Only wipe the metadata and not the whole device"), action="store_true")

sparser=subparsers.add_parser("dev-copy", help=_("Makes a byte for byte copy of a device to a file (like dd) or vice-versa"))
sparser.add_argument("infile", help=_("Input file (or device) or admin build configuration"))
sparser.add_argument("outfile", help=_("File (or device) to copy data to"))

sparser=subparsers.add_parser("dev-run-in-vm", help=_("Starts an INSECA device in a VM"))
sparser.add_argument("devfile", nargs='?', default=None, help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("--bios", help=_("Boot in Legacy BIOS mode instead of UEFI"), action="store_true")
sparser.add_argument("--mem", help=_("Quantity of RAM to allocate to the VM in Mib (2048 by default)"))

sparser=subparsers.add_parser("dev-mount", help=_("Mount a partition of an INSECA device"))
sparser.add_argument("devfile", nargs='?', default=None, help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("partition_id", metavar="partition-id", help=_("Partition ID name to mount"))
sparser.add_argument("mountpoint", help=_("Directory where the partition will be mounted"))
sparser.add_argument("--decrypt_key", metavar="decrypt-key", help=_("Force a specific decryption key to get the protected data"))

sparser=subparsers.add_parser("dev-umount", help=_("Unmount a mounted partition of an INSECA device"))
sparser.add_argument("devfile", nargs='?', default=None, help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("partition_id", nargs='?', default="-", metavar="partition-id", help=_("Partition ID (name) to umount, pass '-' to unmount all"))

sparser=subparsers.add_parser("dev-users", help=_("List the users declared"))
sparser.add_argument("devfile", help=_("Device's associated file (e.g. /dev/sda)"))

sparser=subparsers.add_parser("dev-user-add", help=_("Add a new user"))
sparser.add_argument("devfile", help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("user", help=_("User to add"))
sparser.add_argument("--password", help=_("Password (use '-' to get from stdin)"))
sparser.add_argument("--passenv", help=_("Name of the environment variable containing the password"))

sparser=subparsers.add_parser("dev-user-del", help=_("Delete a user"))
sparser.add_argument("devfile", help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("user", help=_("User to delete"))

sparser=subparsers.add_parser("dev-user-password", help=_("Reset the user's password"))
sparser.add_argument("devfile", help=_("Device's associated file (e.g. /dev/sda)"))
sparser.add_argument("user", help=_("User for which the password will be reset"))
sparser.add_argument("--password", help=_("Password to use (use '-' if provided via stdin)"))
sparser.add_argument("--passenv", help=_("Name of the environment variable containing the password"))

sparser=subparsers.add_parser("dev-check", help=_("Check a device's integrity and display any error"))
sparser.add_argument("devfile", nargs='?', default=None, help=_("Device's associated file (e.g. /dev/sda)"))

# list commands which require to be run as root
root_required_commands=["build", "dev-install", "gen-admin-iso",
                        "dev-update-linux", "dev-format", "dev-ident", "dev-copy",
                        "dev-wipe", "dev-run-in-vm", "dev-mount", "dev-umount",
                        "dev-users", "dev-user-add", "dev-user-del", "dev-user-password", "dev-check"]

def _print_status(conf:confs.ConfigInterface, prefix:str=_indent) -> None:
    for txt in conf.status.warnings:
        print(f"{prefix}W: {txt}")
    for txt in conf.status.errors:
        print(f"{prefix}E: {txt}")
    for txt in conf.status.todo:
        print(f"{prefix}T: {txt}")

def _format_conf_oneline(conf:confs.ConfigInterface) -> str:
    return f"{conf.id} ({conf.descr if conf.descr is not None else '--no description--'}){', NON VALID' if not conf.status.valid else ''}"

def show_status(args):
    if not "INSECA_ROOT" in os.environ:
        raise Exception(_("No root path to the global configuration specified (INSECA_ROOT environment variable or '--root' option"))
    root=os.environ["INSECA_ROOT"]
    if not os.path.exists("%s/inseca.json"%root):
        raise Exception(_("Not yet configured, use the 'init' command"))
    gconf=confs.GlobalConfiguration()
    print(_("Global configuration Ok (%s)")%(_("master") if gconf.is_master else _("not master")))
    print(_("Configuration directory: %s")%gconf.path)
    print(_("Proxy PAC file: %s")%(gconf.proxy_pac_file if gconf.proxy_pac_file else "--"))

    conf_list=gconf.build_configs
    print(_(f"{len(conf_list)} build configuration(s)"))
    for uid in conf_list:
        conf=gconf.get_build_conf(uid)
        print(f"{_indent}{_format_conf_oneline(conf)}")
        if args.verbose:
            _print_status(conf, _indent*2)

    conf_list=gconf.install_configs
    print(f"{len(conf_list)} install configuration(s)")
    for uid in conf_list:
        conf=gconf.get_install_conf(uid)
        print(f"{_indent}{_format_conf_oneline(conf)}")
        if args.verbose:
            _print_status(conf, _indent*2)

    conf_list=gconf.format_configs
    print(f"{len(conf_list)} format configuration(s)")
    for uid in conf_list:
        conf=gconf.get_format_conf(uid)
        print(f"{_indent}{_format_conf_oneline(conf)}")
        if args.verbose:
            _print_status(conf, _indent*2)

    conf_list=gconf.domain_configs
    print(f"{len(conf_list)} domain configuration(s)")
    for uid in conf_list:
        conf=gconf.get_domain_conf(uid)
        print(f"{_indent}{_format_conf_oneline(conf)}")
        if args.verbose:
            _print_status(conf, _indent*2)

    conf_list=gconf.repo_configs
    nb=0
    for ruid in conf_list:
        rconf=gconf.get_repo_conf(ruid)
        if rconf.type==confs.RepoType.USERDATA:
            nb+=1
    print(f"{nb} USERDATA configuration(s)")
    for ruid in conf_list:
        conf=gconf.get_repo_conf(ruid)
        if conf.type==confs.RepoType.USERDATA:
            print(f"{_indent}{_format_conf_oneline(conf)}")
            if args.verbose:
                _print_status(conf, _indent*2)

    Sync.proxy_pac_file=gconf.proxy_pac_file
    sobjects=gconf.get_all_sync_objects(gconf.is_master)
    if len(sobjects)==0:
        print("No %s configuration defined"%("upload (sync-push)" if gconf.is_master else "download (sync-pull)"))
    else:
        print("%s configurations:"%("Upload (sync-push)" if gconf.is_master else "Download (sync-pull)"))
        for sobj in sobjects:
            local_st=sobj.root_conf if sobj.is_local else "cloud"
            print(f"{_indent}{sobj.name} ('{local_st}',{'' if sobj.is_available else 'NOT'} available)")

def init(args):
    # initialize a new INSECA installation
    confs.init_root_config()

    # initialize the Git files
    gconf=confs.get_gconf()
    if shutil.which("git"):
        util.print_event("Initializing Git")
        (status, out, err)=util.exec_sync(["git", "init"], cwd=gconf.path)
        if status!=0:
            util.print_event("Error initializing Git: %s"%err)
        util.write_data_to_file(".borg\nBUILD\nrepos\n*.iso\n*.userdata-specs\n*~\n*#\n", "%s/.gitignore"%gconf.path)

def list_configs(args):
    ctype=args.type
    gconf=confs.GlobalConfiguration()
    if ctype=="build":
        configs=gconf.build_configs
        for uid in configs:
            conf=gconf.get_build_conf(uid)
            print(_format_conf_oneline(conf))
            if args.verbose:
                _print_status(conf)
    elif ctype=="install":
        configs=gconf.install_configs
        for uid in configs:
            conf=gconf.get_install_conf(uid)
            print(_format_conf_oneline(conf))
            if args.verbose:
                _print_status(conf)
    elif ctype=="format":
        configs=gconf.format_configs
        for uid in configs:
            conf=gconf.get_format_conf(uid)
            print(_format_conf_oneline(conf))
            if args.verbose:
                _print_status(conf)
    elif ctype=="domain":
        configs=gconf.domain_configs
        for uid in configs:
            conf=gconf.get_domain_conf(uid)
            print(_format_conf_oneline(conf))
            if args.verbose:
                _print_status(conf)
    elif ctype=="userdata":
        configs=gconf.repo_configs
        for uid in configs:
            conf=gconf.get_repo_conf(uid)
            if conf.type==confs.RepoType.USERDATA:
                print(_format_conf_oneline(conf))
                if args.verbose:
                    _print_status(conf)
    elif ctype=="repo":
        configs=gconf.repo_configs
        for type in confs.RepoType:
            print("%s repositories:"%type.value.upper())
            for uid in configs:
                rconf=gconf.get_repo_conf(uid)
                if rconf.type==type:
                    refs=rconf.get_referenced_by_configurations()
                    if len(refs)==0:
                        print(f"{_indent}{_format_conf_oneline(rconf)}: orphaned")
                    elif len(refs)==1:
                        print(f"{_indent}{_format_conf_oneline(rconf)}, used by {_format_conf_oneline(refs[0])}")
                    else:
                        print(f"{_indent}{_format_conf_oneline(rconf)}, used by:")
                        for ref in refs:
                            print(f"{_indent*2}{_format_conf_oneline(ref)}")
                if args.verbose:
                    _print_status(rconf)
    else:
        raise Exception("Unknown config type '%s"%ctype)

def config_create(args):
    # common name and description arguments
    gconf=confs.GlobalConfiguration()
    descr=args.description

    created_conf=None
    if args.type=="admin-build":
        created_conf=confs.BuildConfig.create_new(gconf, descr, confs.BuildType.ADMIN)

    elif args.type=="build":
        created_conf=confs.BuildConfig.create_new(gconf, descr)

    elif args.type=="install":
        if args.build is None:
            raise Exception("Build configuration must be specified")
        build_conf=gconf.get_build_conf(args.build)
        created_conf=confs.InstallConfig.create_new(gconf, descr, extra=build_conf)

    elif args.type=="format":
        created_conf=confs.FormatConfig.create_new(gconf, descr)

    elif args.type=="domain":
        created_conf=confs.DomainConfig.create_new(gconf, descr, confs.RepoType.DOMAIN)

    elif args.type=="userdata":
        created_conf=confs.RepoConfig.create_new(gconf, descr, confs.RepoType.USERDATA)
    else:
        raise Exception("Unknown config. type '%s'"%args.type)

    # print result
    (status, out, err)=util.exec_sync([prog_path, "config-infos", created_conf])
    if status==0:
        print("%s"%out)
    else:
        raise Exception(err)

def config_clone(args):
    uid=args.config
    descr=args.description
    target_root=args.other_root
    gconf=confs.GlobalConfiguration()
    conf=gconf.get_any_conf(uid, exception_if_not_found=True)

    map={}
    if target_root is None:
        target_gconf=None
    else:
        target_gconf=confs.GlobalConfiguration(target_root)
        if isinstance(conf, confs.InstallConfig):
            if conf.build_id is not None:
            # we need to also clone the associated build configuration
                print(f"Cloning {conf.build_id}")
                bconf=conf.global_conf.get_build_conf(conf.build_id)
                nbuid=bconf.clone(target_gconf, bconf.descr, map)
                print(f"{conf.build_id} cloned as {nbuid}")
    
    if target_gconf is None:
        print(f"Cloning {uid} as '{descr}'")
    else:
        print(f"Cloning {uid} to {target_gconf.path} as '{descr}'")
    cloned_conf=conf.clone(target_gconf, descr, map)

    # print result
    if target_gconf is None:
        (status, out, err)=util.exec_sync([prog_path, "config-infos", cloned_conf])
        if status==0:
            print("%s"%out)
        else:
            raise Exception(err)
    else:
        print(f"Created configuration {cloned_conf}")

def config_remove(args):
    if args.verbose:
        util.print_events=True

    gconf=confs.get_gconf()
    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, can't remove configurations")

    if len(args.config)==0:
        raise Exception("No configuration to remove has been specified")

    def _request_confirmation(conf:confs.ConfigInterface):
        if isinstance(conf, confs.BuildConfig):
            c=input("Confirm removal of build configuration '%s' (enter YES):"%conf.descr)
        elif isinstance(conf, confs.InstallConfig):
            c=input("Confirm removal of install configuration '%s' (enter YES):"%conf.descr)
        elif isinstance(conf, confs.FormatConfig):
            c=input("Confirm removal of format configuration '%s' (enter YES):"%conf.descr)
        elif isinstance(conf, confs.RepoConfig):
            if conf.type==confs.RepoType.USERDATA:
                c=input("Confirm removal of USERDATA repository configuration '%s' (enter YES):"%conf.descr)
            return True
        elif isinstance(conf, confs.DomainConfig):
            c=input("Confirm removal of domain configuration '%s' (enter YES):"%conf.descr)
        return c=="YES"

    # remove the specified configs
    for uid in args.config:
        conf=gconf.get_any_conf(uid)
        to_be_removed=[]
        to_keep=[]

        # check if the configuration is currently needed by another configuration
        byrefs=conf.get_referenced_by_configurations()
        if len(byrefs)>0:
            for ref in byrefs:
                print(f"Configuration needed by {ref.id}: {ref.descr}")
            raise Exception("Configuration can't be removed")

        # one can't remove a non USERDATA repo directly
        if isinstance(conf, confs.RepoConfig) and conf.type!=confs.RepoType.USERDATA:
            raise Exception("Directly removing a repository is not allowed")

        # check if any of the referenced configuration is currently needed by another configuration
        refs=conf.get_referenced_configurations()
        for ref in refs:
            keep=True
            byrefs=ref.get_referenced_by_configurations()
            if byrefs==[] or byrefs==[conf]:
                if isinstance(ref, confs.RepoConfig):
                    if ref.type==confs.RepoType.USERDATA:
                        print(f"NB: Configuration {ref.id} ({ref.descr}) will be kept as it is a USERDATA repo. configuration")
                    else:
                        keep=False
                else:
                    print(f"NB: Configuration {ref.id} ({ref.descr}) will be kept as it is not a repos. configuration")
            else:
                for bref in byrefs:
                    if bref!=conf:
                        print(f"NB: Configuration {ref.id} ({ref.descr}) will be kept as it is used by {bref.id} ({bref.descr})")
            if keep:
                to_keep.append(ref)
            else:
                to_be_removed.append(ref)

        if not args.confirm and not _request_confirmation(conf):
            raise Exception("Cancelled")
        to_be_removed.append(conf)

        # actual removal of configurations
        for conf in to_be_removed:
            print(f"Removing configuration {conf.id}: {conf.descr}")
            conf.remove(to_keep)

def _print_repo_archives(rconf, indent=""):
    try:
        arlist=rconf.get_all_archives()
        tslist=list(arlist.keys())
        tslist.sort(reverse=True)
        for ts in tslist:
            print("%s@%s: %s"%(indent, util.format_timestamp(ts), arlist[ts]))
    except Exception:
        pass

def config_infos(args):
    uid=args.config
    gconf=confs.GlobalConfiguration()
    conf=gconf.get_any_conf(uid, exception_if_not_found=False)

    # build configuration ?
    if isinstance(conf, confs.BuildConfig):
        print("Build configuration ID: %s"%conf.id)
        print("Build type: %s"%conf.build_type.value)
        print("Description: %s"%conf.descr)
        print("Configuration file: %s"%conf.config_file)
        print("Build directory: %s/%s"%(conf.build_dir, conf.id))
        print("Repo ID: %s"%conf.repo_id)
        if "signature" not in conf.components:
            print("Builds are not signed (the 'signature' component is not present)")
        if conf.repo_id:
            rconf=gconf.get_repo_conf(conf.repo_id, exception_if_not_found=False)
            if rconf is not None:
                print("Live Linux archives:")
                _print_repo_archives(rconf, _indent)

            iconfs=gconf.install_configs
            print("Referenced by installation configurations:")
            for iuid in iconfs:
                iconf=gconf.get_install_conf(iuid)
                if iconf.build_id==uid:
                    print(f"{_indent}{_format_conf_oneline(iconf)}")

        if conf.status.valid:
            print("Configuration is valid")
        else:
            print("Configuration needs to be corrected")
        _print_status(conf)
        return

    # install configuration ?
    if isinstance(conf, confs.InstallConfig):
        print("Install configuration ID: %s"%conf.id)
        print("Description: %s"%conf.descr)
        print("Configuration file: %s"%conf.config_file)
        print("Repo ID: %s"%conf.repo_id)
        rconf=gconf.get_repo_conf(conf.repo_id, exception_if_not_found=False)
        if rconf is not None:
            print("Install archives:")
            _print_repo_archives(rconf, indent=_indent)

        print(f"Build configuration ID: {conf.build_id}")
        print(f"Build repository ID: {conf.build_repo_id}")

        if conf.status.valid:
            print("Configuration is valid")
        else:
            print("Configuration needs to be corrected")
        _print_status(conf)
        return

    # format configuration ?
    if isinstance(conf, confs.FormatConfig):
        print("Format configuration ID: %s"%conf.id)
        print("Description: %s"%conf.descr)
        print("Configuration file: %s"%conf.config_file)
        print("Repo ID: %s"%conf.repo_id)
        rconf=gconf.get_repo_conf(conf.repo_id, exception_if_not_found=False)
        if rconf is not None:
            print("Archives of this format config:")
            _print_repo_archives(rconf, indent=_indent)

        if conf.status.valid:
            print("Configuration is valid")
        else:
            print("Configuration needs to be corrected")
        _print_status(conf)
        return

    # domain configuration ?
    if isinstance(conf, confs.DomainConfig):
        print("Domain configuration ID: %s"%conf.id)
        print("Description: %s"%conf.descr)
        print("Configuration file: %s"%conf.config_file)
        print("Repo ID: %s"%conf.repo_id)
        print(f"Referenced installation configurations: {'---' if len(conf.install_ids)==0 else ''}")
        for iuid in conf.install_ids:
            iconf=gconf.get_install_conf(iuid, exception_if_not_found=False)
            if iconf is not None:
                print(f"{_indent}{_format_conf_oneline(iconf)}")
            else:
                print(f"{_indent}ERROR: referenced installation configuration '{iuid}' not found")
        print(f"Referenced format configurations: {'---' if len(conf.format_ids)==0 else ''}")
        for iuid in conf.format_ids:
            iconf=gconf.get_format_conf(iuid, exception_if_not_found=False)
            if iconf is not None:
                print(f"{_indent}{_format_conf_oneline(iconf)}")
            else:
                print(f"{_indent}ERROR: corresponding format configuration '{iuid}' not found")
        rconf=gconf.get_repo_conf(conf.repo_id, exception_if_not_found=False)
        if rconf is not None:
            print("Archives of this domain config:")
            _print_repo_archives(rconf, indent=_indent)

        if conf.status.valid:
            print("Configuration is valid")
        else:
            print("Configuration needs to be corrected")
        _print_status(conf)
        return

    # repo configuration ?
    if isinstance(conf, confs.RepoConfig):
        print("Repository configuration ID: %s"%conf.id)
        print("Description: %s"%conf.descr if conf.descr is not None else "--no description--")
        print("Configuration file: %s"%conf.config_file)
        print("Repository type: %s"%str(conf.type))
        print("Data path: %s"%conf.path)
        print("Size: %s"%conf.used_space)

        refs=conf.get_referenced_by_configurations()
        if len(refs)==0:
            print(f"Not used by any configuration (orphaned)")
        elif len(refs)==1:
            print(f"Used by: {_format_conf_oneline(refs[0])}")
        else:
            print(f"Used by:")
            for ref in refs:
                print(f"{_indent}{_format_conf_oneline(ref)}")

        env=conf.get_borg_exec_env()
        if args.verbose:
            print("Usage environment:")
            for name in env:
                if name.startswith("BORG_"):
                    print(f"{_indent}export {name}={shlex.quote(env[name])}")
        print("Archives in repository:")
        _print_repo_archives(conf, indent=_indent)

        if conf.status.valid:
            print("Configuration is valid")
        else:
            print("Configuration needs to be corrected")
        _print_status(conf)
        return

    raise Exception("Config '%s' not found"%uid)

def repo_ls(args):
    uid=args.repo
    if args.archive is None:
        gconf=confs.GlobalConfiguration()
        rconf=gconf.get_repo_conf(uid)
        _print_repo_archives(rconf)
    else:
        gconf=confs.GlobalConfiguration()
        rconf=gconf.get_repo_conf(uid)
        data=rconf.borg_repo.list_archive_contents(args.archive)
        print("%s"%data)

def _sync_push(rconf, sync_obj):
    src=Sync.SyncLocation(rconf.path, None)
    dest=Sync.SyncLocation(rconf.id, sync_obj)
    so=Sync.RcloneSync(src, dest, rconf.get_borg_exec_env())
    so.sync()

def _sync_pull(rconf, sync_obj):
    assert isinstance(rconf, confs.RepoConfig)
    src=Sync.SyncLocation(rconf.id, sync_obj)
    dest=Sync.SyncLocation(rconf.path, None)
    counter=5
    while True:
        try:
            util.print_event("Downloading '%s'"%rconf.descr)
            so=Sync.RcloneSync(src, dest, rconf.get_borg_exec_env())
            so.sync()
            util.print_event("Checking downloaded data's validity")
            rconf.borg_repo.check() # ensure repo is useable
            break
        except Sync.ResourceNotAvailable as e:
            if counter>0:
                util.print_event("Resource currently not available")
                counter-=1
                time.sleep(2)
            else:
                raise e

def _get_associated_repo_configurations(uid:str) -> list[confs.RepoConfig]:
    """Get a list of repositorie configurations associated to the
    @uid configuration:
    - if the @uid configuration is a RepoConfig, then return it
    - otherwise return all the RepoConfig referenced by the @uid configuration
    """
    gconf=confs.GlobalConfiguration()
    conf=gconf.get_any_conf(uid)
    if isinstance(conf, confs.RepoConfig):
        return [conf]
    else:
        res=[]
        for cref in conf.get_referenced_configurations():
            if isinstance(cref, confs.RepoConfig):
                res.append(cref)
        return res

def sync_push(args):
    """Push a repository (or all repositories if not specified) to a target location"""
    if args.verbose:
        util.print_events=True
    gconf=confs.GlobalConfiguration()
    Sync.proxy_pac_file=gconf.proxy_pac_file

    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, cannot push repository's contents")

    target=args.storage
    sync=gconf.get_target_sync_object(target, True) # write to outside location
    if args.repos==[]:
        repos=gconf.repo_configs
    else:
        repos=args.repos

    for uid in repos:
        for rconf in _get_associated_repo_configurations(uid):
            print(f"Pushing {_format_conf_oneline(rconf)}, {rconf.type.value.upper()}")
            _sync_push(rconf, sync)

def sync_pull(args):
    """Using the defined domain configuration(s), update the whole local configuration"""
    if args.verbose:
        util.print_events=True
    gconf=confs.GlobalConfiguration()

    if gconf.is_master:
        raise Exception("Installation is a master configuration, cannot update")

    target=args.storage
    sync=gconf.get_target_sync_object(target, False) # read from outside location

    # create TMP directory for the new configuration, which will replace the current one in the end
    newconfdir=gconf.create_update_dir()

    # update and extract all DOMAIN repos present in the config dir
    for ruid in gconf.repo_configs:
        try:
            rconf=gconf.get_repo_conf(ruid)
            if rconf.type==confs.RepoType.DOMAIN:
                _sync_pull(rconf, sync)
                (ts, lastarname)=rconf.get_latest_archive()
                if lastarname:
                    rconf.extract_archive(lastarname, newconfdir)
        except Exception as e:
            # ignore error, do as best as we can
            util.print_event(f"Could not download resource: {str(e)}")

    # create new GlobalConfiguration from the extracted data
    ngconf=confs.GlobalConfiguration(path=newconfdir)

    # update all repo's contents
    updated_repos=[]
    for ruid in ngconf.repo_configs:
        try:
            rconf=ngconf.get_repo_conf(ruid)
            _sync_pull(rconf, sync)
            updated_repos+=[rconf.id]
        except Exception as e:
            # ignore error, do as best as we can
            util.print_event(f"Could not download resource: {str(e)}")
    ngconf=confs.GlobalConfiguration(path=newconfdir)

    # for each INSTALL and FORMAT repo: extract the corresponding data from the last archive
    util.print_event("Extracting INSTALL and FORMAT archives")
    for iuid in ngconf.install_configs + ngconf.format_configs:
        try:
            conf=ngconf.get_install_conf(iuid)
        except:
            conf=ngconf.get_format_conf(iuid)
        rconf=ngconf.get_repo_conf(conf.repo_id)
        (ts, lastarname)=rconf.get_latest_archive()
        if lastarname:
            util.print_event("Extracting '%s'"%rconf.descr)
            #print("config dir: %s"%conf.config_dir)
            rconf.extract_archive(lastarname, conf.config_dir)

    # remove obsolete repos
    repos_dir=gconf.path+"/repo-configurations"
    for dname in os.listdir(repos_dir):
        try:
            data=json.load(open("%s/%s"%(repos_dir, dname), "r"))
            ruid=data["id"]
            if ruid not in updated_repos:
                print("Removing repo %s"%ruid)
                orconf=gconf.get_repo_conf(ruid)
                util.print_event("Removing '%s'"%orconf.descr)
                orconf.remove()
        except Exception as e:
            util.print_event("Could not remove repo. %s: %s"%(ruid, str(e)))

    # finish replacing the current configuration
    gconf.merge_update()

    # extract last archive of BUILD and USERDATA repos
    util.print_event("Extracting last BUILD and USERDATA archives")
    ngconf=confs.GlobalConfiguration()
    for ruid in updated_repos:
        rconf=ngconf.get_repo_conf(ruid)
        if rconf.type in (confs.RepoType.BUILD, confs.RepoType.USERDATA):
            util.print_event("Extracting '%s'"%rconf.descr)
            rconf.cache_last_archive()

def repo_prune(args):
    """Remove obsolete archives in repositories"""
    gconf=confs.GlobalConfiguration()

    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, can't prune repositories")

    if args.repos==[]:
        repos=gconf.repo_configs
    else:
        repos=args.repos

    if args.empty: # remove all contents in the repo
        if not args.confirm:
            c=input("Confirm removing all archives in repo (enter YES):")
            if c!="YES":
                print("Cancelled")
                return

    # handle all repos
    for ruid in repos:
        for rconf in _get_associated_repo_configurations(ruid):
            print("Analysing repository '%s'"%rconf.id)
            arlist=rconf.get_all_archives()
            if len(arlist)>0:
                if args.empty:
                    # remove all archives
                    tslist=list(arlist.keys())
                    for ts in tslist:
                        arname=arlist[ts]
                        print("Repository %s (%s): removing archive %s"%(ruid, rconf.descr, arname))
                        rconf.borg_repo.delete_archive(arname)
                else:
                    # keep only the latest and greatest archive in the repo
                    tslist=list(arlist.keys())
                    tslist.sort(reverse=True)
                    for ts in tslist[1:]:
                        arname=arlist[ts]
                        print("Repository %s (%s): removing archive %s"%(ruid, rconf.descr, arname))
                        rconf.borg_repo.delete_archive(arname)
                print("Repository %s (%s): cleanups"%(ruid, rconf.descr))
                rconf.borg_repo.vacuum()


def _publish_build(bconf):
    files=(bconf.image_iso_file, bconf.image_userdata_specs_file)
    for path in files:
        if not os.path.exists(path):
            raise Exception(_("Missing live Linux file '%s'")%path)
    arpath=os.path.dirname(bconf.image_iso_file)
    if arpath!=os.path.dirname(bconf.image_userdata_specs_file):
        raise Exception("CODEBUG: ISO and USERDATA specs. file not in the same directory")

    # check repo
    if not bconf.repo_id:
        raise Exception(_("Build configuration does not specify a repository"))
    gconf=confs.get_gconf()
    rconf=gconf.get_repo_conf(bconf.repo_id)
    if rconf.type != confs.RepoType.BUILD:
        raise Exception(_("Build configuration specifies a non BUILD repository"))

    # signing if specified
    skey_file=bconf.signing_privkey
    if skey_file is not None:
        util.print_event(_("Signing live Linux"))
        sobj=x509.CryptoKey(util.load_file_contents(skey_file), None)
        # sign the live Linux ISO
        hash=cgen.compute_hash_file(bconf.image_iso_file)
        sig=sobj.sign(hash)
        util.write_data_to_file(sig, "%s.sign"%bconf.image_iso_file)
        # sign the USERDATA specs. file
        hash=cgen.compute_hash_file(bconf.image_userdata_specs_file)
        sig=sobj.sign(hash)
        util.write_data_to_file(sig, "%s.sign"%bconf.image_userdata_specs_file)
        # sign the infos.json
        hash=cgen.compute_hash_file(bconf.image_infos_file)
        sig=sobj.sign(hash)
        util.write_data_to_file(sig, "%s.sign"%bconf.image_infos_file)
    else:
        util.print_event(_("Not signing live Linux (configuration does not specify any signing key)"))

    # adding archive
    rconf.borg_repo.create_archive(arpath, rconf.compress)

    # cleanups
    os.remove(bconf.image_iso_file)
    os.remove("%s.sign"%bconf.image_iso_file)
    os.remove(bconf.image_userdata_specs_file)
    os.remove("%s.sign"%bconf.image_userdata_specs_file)
    os.remove(bconf.image_infos_file)
    os.remove("%s.sign"%bconf.image_infos_file)


def _publish_install(iconf):
    # copy the install's directory's contents
    tmp=tempfile.TemporaryDirectory()
    tmptar=tempfile.NamedTemporaryFile()
    tarobj=tarfile.open(tmptar.name, mode='w')
    tarobj.add(iconf.config_dir, arcname=".", recursive=True)
    tarobj.close()
    tarobj=tarfile.open(tmptar.name, mode='r')
    tarobj.extractall(tmp.name)

    # create borg archive
    gconf=confs.get_gconf()
    rconf=gconf.get_repo_conf(iconf.repo_id)
    rconf.borg_repo.create_archive(tmp.name, rconf.compress)

def _publish_format(fconf):
    # copy the format's directory's contents
    tmp=tempfile.TemporaryDirectory()
    tmptar=tempfile.NamedTemporaryFile()
    tarobj=tarfile.open(tmptar.name, mode='w')
    tarobj.add(fconf.config_dir, arcname=".", recursive=True)
    tarobj.close()
    tarobj=tarfile.open(tmptar.name, mode='r')
    tarobj.extractall(tmp.name)

    # create borg archive
    gconf=confs.get_gconf()
    rconf=gconf.get_repo_conf(fconf.repo_id)
    rconf.borg_repo.create_archive(tmp.name, rconf.compress)

def _publish_domain(dconf):
    """Add a new domain achive.
    It contains all the files necessary to generate INSECA installations, where all the repositories's path are replaced by
    the relative path '<repo-ID>'
    """
    # create temp directory where all the files which will be pushed to the repo will be
    builddir=tempfile.TemporaryDirectory()
    (status, out, err)=util.exec_sync([prog_path, "--root", builddir.name, "init"])
    if status!=0:
        raise Exception("Could not initialize empty global configuration structure: %s"%err)

    # copy domain configuration itself
    shutil.copyfile(dconf.config_file, "%s/domain-configurations/%s"%(builddir.name, os.path.basename(dconf.config_file)))

    # copy associated repo's configuration
    gconf=confs.get_gconf()
    rconf=gconf.get_repo_conf(dconf.repo_id)
    util.write_data_to_file(json.dumps(rconf.export(new_path=rconf.id), indent=4),
                                        "%s/repo-configurations/%s.json"%(builddir.name, str(rconf.id)))

    # copy required data from each install ref
    for iuid in dconf.install_ids:
        iconf=gconf.get_install_conf(iuid)

        # copy install configuration
        confdir=os.path.dirname(iconf.config_file)
        idir="%s/install-configurations/%s"%(builddir.name, os.path.basename(confdir))
        os.makedirs(idir)
        shutil.copyfile(iconf.config_file, "%s/%s"%(idir, os.path.basename(iconf.config_file)))

        # copy associated repo's configuration
        rconf=gconf.get_repo_conf(iconf.repo_id)
        util.write_data_to_file(json.dumps(rconf.export(new_path=rconf.id), indent=4),
                                            "%s/repo-configurations/%s.json"%(builddir.name, str(rconf.id)))

        # copy associated build repo's configuration
        rconf=gconf.get_repo_conf(iconf.build_repo_id)
        util.write_data_to_file(json.dumps(rconf.export(new_path=rconf.id), indent=4),
                                            "%s/repo-configurations/%s.json"%(builddir.name, str(rconf.id)))

        # copy userdata repos' configurations
        for component in iconf.userdata:
            for key in iconf.userdata[component]:
                value=iconf.userdata[component][key]
                if value is None:
                    raise Exception("No repository configuration specified for component '%s' and userdata '%s'"%(component, key))
                rconf=gconf.get_repo_conf(value, exception_if_not_found=False)
                if rconf:
                    util.write_data_to_file(json.dumps(rconf.export(new_path=rconf.id), indent=4),
                                                        "%s/repo-configurations/%s.json"%(builddir.name, str(rconf.id)))

    # copy required data from each format ref
    for fuid in dconf.format_ids:
        fconf=gconf.get_format_conf(fuid)

        # copy format configuration
        confdir=os.path.dirname(fconf.config_file)
        fdir="%s/format-configurations/%s"%(builddir.name, os.path.basename(confdir))
        os.makedirs(fdir)
        shutil.copyfile(fconf.config_file, "%s/%s"%(fdir, os.path.basename(fconf.config_file)))

        # copy associated repo's configuration
        rconf=gconf.get_repo_conf(fconf.repo_id)
        util.write_data_to_file(json.dumps(rconf.export(new_path=rconf.id), indent=4),
                                            "%s/repo-configurations/%s.json"%(builddir.name, str(rconf.id)))

    # create global config file
    deploy={}
    for obj in gconf.get_all_sync_objects(False):
        deploy[obj.name]={
            "root": obj.root_conf
        }
        if obj.conf_file is not None:
            bname=os.path.basename(obj.conf_file)
            if not os.path.isfile(obj.conf_file):
                raise Exception("Missing storage credential file '%s'"%obj.conf_file)
            shutil.copyfile(obj.conf_file, "%s/storage-credentials/%s"%(builddir.name, bname))
        else:
            bname=None
        deploy[obj.name]["reader-conf"]=bname
    data={
        "deploy": deploy,
        "is-master": False
    }
    util.write_data_to_file(json.dumps(data, indent=4), "%s/inseca.json"%builddir.name)

    # include proxy PAC if defined AND is below the INSECA_ROOT directory
    pfile=gconf.proxy_pac_file
    if pfile and pfile.startswith(gconf.path):
        shutil.copyfile(pfile, "%s/proxy.pac"%builddir.name)

    # create borg archive
    rconf=gconf.get_repo_conf(dconf.repo_id)
    rconf.borg_repo.create_archive(builddir.name, rconf.compress)

def _config_publish_one(gconf, uid):
    """Publish a single config specified by its UID"""
    # build configuration ?    
    conf=gconf.get_build_conf(uid, exception_if_not_found=False)
    if conf:
        _publish_build(conf)
        return
    
    # install configuration ?    
    conf=gconf.get_install_conf(uid, exception_if_not_found=False)
    if conf:
        _publish_install(conf)
        return

    # format configuration ?    
    conf=gconf.get_format_conf(uid, exception_if_not_found=False)
    if conf:
        _publish_format(conf)
        return

    # domain configuration ?    
    conf=gconf.get_domain_conf(uid, exception_if_not_found=False)
    if conf:
        _publish_domain(conf)
        return

    raise Exception("Configuration '%s' can't be published"%uid)

def config_publish(args):
    if args.verbose:
        util.print_events=True
    gconf=confs.get_gconf()
    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, can't publish")

    if len(args.config)>0:
        # publish the specified configs
        for uid in args.config:
            util.print_event("Publishing config '%s'"%uid)
            _config_publish_one(gconf, uid)
    else:
        # publish all configs (not repo ones!)
        for uid in gconf.build_configs:
            conf=gconf.get_build_conf(uid)
            if conf.repo_id and os.path.exists(conf.image_iso_file):
                util.print_event("Publishing config '%s'"%uid)
                _publish_build(conf)
        for uid in gconf.install_configs:
            conf=gconf.get_install_conf(uid)
            util.print_event("Publishing config '%s'"%uid)
            _publish_install(conf)
        for uid in gconf.format_configs:
            conf=gconf.get_format_conf(uid)
            util.print_event("Publishing config '%s'"%uid)
            _publish_format(conf)
        for uid in gconf.domain_configs:
            conf=gconf.get_domain_conf(uid)
            util.print_event("Publishing config '%s'"%uid)
            _publish_domain(conf)

def userdata_import(args):
    """Adds an archive to a USERDATA repository"""
    repo_id=args.repo
    data_path=args.path
    gconf=confs.GlobalConfiguration()

    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, can't import userdata")

    rconf=gconf.get_repo_conf(repo_id)
    if rconf.type != confs.RepoType.USERDATA:
        raise Exception("Invalid non USERDATA repository")
    if not os.path.isdir(data_path):
        raise Exception("'%s' is not a directory (or does not exist)"%data_path)
    rconf.borg_repo.create_archive(data_path, rconf.compress)

def userdata_add(args):
    gconf=confs.GlobalConfiguration()

    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, can't add userdata")

    rconf=gconf.get_repo_conf(args.repo)
    if rconf.type!=confs.RepoType.USERDATA:
        raise Exception("Invalid non USERDATA repository")
    if not rconf.status.valid:
            raise Exception(f"Configuration {rconf.id} is invalid")
    (ts, last_arname)=rconf.borg_repo.get_latest_archive()

    # check that the file to add actually exist
    files=args.files
    for file in files:
        if not os.path.exists(file):
            raise Exception("File '%s' to add does not exist"%file)
        if not os.path.isfile(file):
            raise Exception("File '%s' to add is not a regular file"%file)

    tmpdir=tempfile.TemporaryDirectory()
    if last_arname is not None:
        # mount last archive and copy all the files in a TMP directory
        mp=rconf.mount(last_arname)
        try:
            tmptar=tempfile.NamedTemporaryFile()
            tarobj=tarfile.open(tmptar.name, mode='w')
            tarobj.add(mp, arcname=".", recursive=True)
            tarobj.close()
            tarobj=tarfile.open(tmptar.name, mode='r')
            tarobj.extractall(tmpdir.name)
        finally:
            rconf.umount(last_arname)

    # add specified files
    for file in files:
        shutil.copyfile(file, "%s/%s"%(tmpdir.name, os.path.basename(file)))

    # create new archive
    rconf.borg_repo.create_archive(tmpdir.name, rconf.compress)

def userdata_del(args):
    ruid=args.repo
    gconf=confs.GlobalConfiguration()

    if not gconf.is_master:
        raise Exception("Installation is not a master configuration, can't delete userdata")

    rconf=gconf.get_repo_conf(ruid)
    if rconf.type!=confs.RepoType.USERDATA:
        raise Exception("Invalid non USERDATA repository")
    (ts, last_arname)=rconf.borg_repo.get_latest_archive()
    if last_arname is None:
        raise Exception("No archive to delete from in repository")

    # mount last archive, check that file to remove are present, and
    # copy all the files in a TMP directory
    tmpdir=tempfile.TemporaryDirectory()
    mp=rconf.mount(last_arname)
    try:
        files=args.files
        for file in files:
            arfile="%s/%s"%(mp, file)
            if not os.path.exists(arfile):
                raise Exception("File '%s' to delete does not exist"%arfile)
            if not os.path.isfile(arfile):
                raise Exception("File '%s' to delete is not a regular file"%arfile)

        tmptar=tempfile.NamedTemporaryFile()
        tarobj=tarfile.open(tmptar.name, mode='w')
        tarobj.add(mp, arcname=".", recursive=True)
        tarobj.close()
        tarobj=tarfile.open(tmptar.name, mode='r')
        tarobj.extractall(tmpdir.name)
    finally:
        rconf.umount(last_arname)

    # remove specified files
    for file in files:
        arfile="%s/%s"%(tmpdir.name, file)
        os.remove(arfile)

    # create new archive
    rconf.borg_repo.create_archive(tmpdir.name, rconf.compress)

def build(args):
    if args.verbose:
        util.print_events=True
    gconf=confs.GlobalConfiguration()
    for buid in args.build:
        bconf=gconf.get_build_conf(buid)
        if not bconf.status.valid:
            raise Exception(f"Configuration {buid} is invalid")
        print(f"Building configuration {_format_conf_oneline(bconf)}")
        builder=LiveBuilder.Builder(buid, args.dry)
        builder.prepare_build_dir()
        builder.copy_resources()
        if args.dry:
            util.write_data_to_file("Not building", builder.build_data_file, append=True)
            print("Not building the Live Linux")
            print("Live build preparation is in: %s"%builder.livedir)
            builder.compute_user_data_specs()
        else:
            cleaned=False
            try:
                builder.build()
                print("Generated file %s"%builder.image_file)
                builder.compute_user_data_specs()
                builder.clean_build_dir()
                cleaned=True
                if args.publish:
                    # publish build if it has been requested
                    if bconf.repo_id and os.path.exists(bconf.image_iso_file):
                        util.print_event("Publishing build '%s'"%buid)
                        _publish_build(bconf)
            finally:
                if not cleaned:
                    builder.clean_build_dir()

def gen_params(args):
    gconf=confs.GlobalConfiguration()
    conf=gconf.get_any_conf(args.config)
    if not conf.status.valid:
        raise Exception(f"Configuration {conf.id} is invalid")
    try:
        if isinstance(conf, confs.InstallConfig):
            (linuximage, linuxuserdata, infos)=gconf.get_install_elements(iconf)
            pset=Installer.ParamsSet(iconf, linuxuserdata)
            templ={"_components": {}}
        elif isinstance(conf, confs.FormatConfig):
            fconf=gconf.get_format_conf(args.config)
            pset=Installer.ParamsSet(fconf)
            templ={}
        else:
            raise Exception(_(f"Configuration {_format_conf_oneline(conf)} is not an install or a format configuration"))

        params=pset.params
        print("Required parameters: %s"%json.dumps(params, indent=4, sort_keys=True))
        for key in params:
            if key=="_components":
                for cname in params["_components"]:
                    templ["_components"][cname]={}
                    for ckey in params["_components"][cname]:
                        entry=params["_components"][cname][ckey]
                        default=""
                        if "default" in entry:
                            default=entry["default"]
                        templ["_components"][cname][ckey]=default
            else:
                entry=params[key]
                default=""
                if "default" in entry:
                    default=entry["default"]
                templ[key]=default
        print("\nTemplate: %s"%json.dumps(templ, indent=4, sort_keys=True))

    finally:
        if isinstance(conf, confs.InstallConfig):
            gconf.release_install_elements(iconf)

def dev_install(args):
    target=args.target
    if args.verbose:
        util.print_events=True
    gconf=confs.GlobalConfiguration()

    # install config specified?
    iconf=gconf.get_install_conf(args.config, exception_if_not_found=False)
    if iconf is not None:
        if not iconf.status.valid:
            raise Exception(f"Configuration {iconf.id} is invalid")
        try:
            (linuximage, linuxuserdata, infos)=gconf.get_install_elements(iconf, args.archive)

            # analyse parameter's values
            paramsf=args.params_file
            if not isinstance(paramsf, str):
                raise Exception(_("The params-file argument is missing"))
            paramsf=os.path.realpath(paramsf)
            if not os.path.exists(paramsf):
                raise Exception("Missing file '%s'"%paramsf)
            try:
                params=json.load(open(paramsf, "r"))
            except Exception:
                raise Exception(_("Invalid or unreadable '%s' file")%paramsf)

            if target.startswith("/dev"):
                creator=Installer.DeviceInstaller(iconf, linuximage, linuxuserdata, params, target, infos)
            else:
                creator=Installer.ImageInstaller(iconf, linuximage, linuxuserdata, params, target, args.vm_size, infos)

            creator.validate()
            creator.install()
            creator=None
        finally:
            # cleanups
            gconf.release_install_elements(iconf, args.archive)
            gc.collect()
        return

    # build config specified?
    bconf=gconf.get_build_conf(args.config, exception_if_not_found=False)
    if bconf is not None:
        if not bconf.status.valid:
            raise Exception(f"Configuration {bconf.id} is invalid")
        if bconf.build_type in (confs.BuildType.WKS, confs.BuildType.SERVER):
            raise Exception("Workstation or server builds must be installed using an install. configuration")
        if args.archive: # use specified archive
            if bconf.repo_id:
                rconf=gconf.get_repo_conf(bconf.repo_id)
                mp=rconf.mount(args.archive)
                iso_file="%s/live-linux.iso"%mp
        else:
            # check there is an existing ISO file
            iso_file=bconf.image_iso_file
            if not os.path.exists(iso_file):
                if bconf.repo_id:
                    # get the ISO file from the latest repo's archive
                    rconf=gconf.get_repo_conf(bconf.repo_id)
                    (ts, arname)=rconf.get_latest_archive()
                    if ts:
                        mp=rconf.mount(arname)
                    iso_file="%s/live-linux.iso"%mp

        if not iso_file:  
            raise Exception("No ISO file available for this build")
        chunk=4*1024*1024 # 4Mib
        size=os.stat(iso_file).st_size
        ndone=0
        nts=0
        try:
            with open(iso_file, "rb") as fd_read:
                with open(target, "wb") as fd_write:
                    while True:
                        data=fd_read.read(chunk)
                        fd_write.write(data)
                        ndone+=len(data)
                        ts=util.get_timestamp()
                        if nts!=ts:
                            util.print_event("%s%% copied"%int(ndone*100/size))
                            nts=ts
                        if ndone==size:
                            break
            util.print_event("Forcing sync.")
            os.sync()
            return
        except Exception as e:
            raise Exception("Error writing ISO image: %s"%str(e))

    raise Exception("Invalid configuration '%s'"%args.config)

def dev_copy(args):
    """Make a dd like copy of a device to a file"""
    infile=args.infile
    outfile=args.outfile
    if args.verbose:
        util.print_events=True

    # if infile is not a file, it may be an admin build configuration, and in
    # this case, we use the built ISO if it exists
    if not os.path.exists(infile):
        gconf=confs.GlobalConfiguration()
        bconf=gconf.get_build_conf(infile, exception_if_not_found=False)
        if bconf is not None:
            if os.path.exists(bconf.image_iso_file):
                infile=bconf.image_iso_file
            else:
                raise Exception("Configuration needs to be built")
        else:
            raise Exception(f"No {infile} file")

    # check we've got enough free space
    size=os.stat(infile).st_size
    outfile=os.path.realpath(outfile)
    stat=shutil.disk_usage(outfile)
    if stat.free<size:
        raise Exception("Can't dump device: not enough free space")

    # umount all devices' partitions, if any
    if infile.startswith("/dev"):
        util.print_event("Unmounting any partition of %s"%infile)
        dev=Device.Device(infile)
        dev.umount_all()
    if outfile.startswith("/dev"):
        util.print_event("Unmounting any partition of %s"%outfile)
        dev=Device.Device(outfile)
        dev.umount_all()

    # copy data
    chunk=4*1024*1024 # 4Mib
    ndone=0
    nts=0
    try:
        with open(infile, "rb") as fd_read:
            with open(outfile, "wb") as fd_write:
                while True:
                    data=fd_read.read(chunk)
                    fd_write.write(data)
                    ndone+=len(data)
                    ts=util.get_timestamp()
                    if nts!=ts:
                        util.print_event("%s%% copied"%int(ndone*100/size))
                        nts=ts
                    if ndone==size:
                        break
        util.print_event("Forcing sync.")
        os.sync()
        return
    except Exception as e:
        raise Exception("Error dumping device: %s"%str(e))

def devices(args):
    """List all mass storage devices, including the internal ones if verbose display requested"""
    devices=util.get_disks()
    for devfile in devices:
        devdata=devices[devfile]
        displ=devdata["useable"]
        if args.verbose:
            displ=True
        if displ:
            if devdata["internal-disk"]:
                print("INTERNAL %s\t%s Gb (%s)"%(devfile, devdata["size-G"], devdata["model"]))
            else:
                print("plugged  %s\t%s Gb (%s)"%(devfile, devdata["size-G"], devdata["model"]))

def dev_update_linux(args):
    if args.target is None:
        args.target=_get_single_useable_device()
    target=args.target
    if args.verbose:
        util.print_events=True

    # get the configuration ID of the device
    gconf=confs.GlobalConfiguration()
    dev=Device.Device(args.target)
    try:
        udata=dev.get_unprotected_data()
        confid=udata["confid"]
        iconf=gconf.get_install_conf(confid)
        util.print_event("Device's installation configuration is: %s"%confid)
        if not iconf.status.valid:
            raise Exception(f"Configuration {iconf.id} is invalid")
    except Exception:
        raise Exception("Could not identify device's configuration")

    # umount all partitions of @target
    Device.umount_all_partitions(target)

    try:
        # get the actual live Linux to use
        (linuximage, linuxuserdata, infos)=gconf.get_install_elements(iconf, args.archive)

        # create updater object and update
        dkey=iconf.password_rescue
        dev.define_a_decryptor(dkey)
        mp_internal=dev.mount(Live.partid_internal)
        mp_dummy=dev.mount(Live.partid_dummy)
        mp_live=dev.mount(Live.partid_live)

        # get the device's associated credentials
        # as pdata["@internal/password"], pdata["@data/password"] and pdata["blob0"]
        pdata=dev.get_protected_data()
        blob0=pdata["blob0"]
        int_password=pdata["@internal/password"]
        data_password=pdata["@data/password"]
        if target.startswith("/dev"):
            updater=Installer.DeviceUpdater(blob0, iconf.signing_pubkey, mp_dummy, mp_live, mp_internal, 
                                            int_password, data_password, linuximage, target)
        else:
            updater=Installer.ImageUpdater(blob0, iconf.signing_pubkey, mp_dummy, mp_live, mp_internal, 
                                           int_password, data_password, linuximage, target)
        updater.update()

        # remove any staged update
        stage_dir="/update-staging"
        stage_dir="%s/%s"%(mp_internal, stage_dir)
        if os.path.exists(stage_dir):
            for fname in os.listdir(stage_dir):
                os.remove("%s/%s"%(stage_dir, fname))
    finally:
        gconf.release_install_elements(iconf, args.archive)

def dev_format(args):
    paramsf=args.params_file
    target=args.target
    if args.verbose:
        util.print_events=True

    gconf=confs.GlobalConfiguration()
    fconf=gconf.get_format_conf(args.format)
    if not fconf.status.valid:
        raise Exception(f"Configuration {fconf.id} is invalid")

    # analyse parameter's values
    paramsf=os.path.realpath(paramsf)
    if not os.path.exists(paramsf):
        raise Exception("Missing file '%s'"%paramsf)
    params=json.load(open(paramsf, "r"))

    # mix all the inputs
    import Installer
    if target.startswith("/dev"):
        creator=Installer.DeviceFormatter(fconf, params, target)
    else:
        raise Exception("Can't format a VM image")

    # actual work
    creator.validate()
    creator.install()
    creator=None
    gc.collect()

def _prepare_config_data(domain_confs, bconf):
    """Prepare a minimal structure for an INSECA global configuration, and incudes:
    - the repo configuration for the domain
    - a valid inseca.json file
    - the PRIVDATA encrypt private key to decrypt any PRIVDATA and component's init code (if @bconf is not None)
    """
    util.print_event("Preparing configuration from specified domain(s)")
    gconf=confs.GlobalConfiguration()
    tmpdir=tempfile.TemporaryDirectory()

    # prepare template
    confdir="%s/configurations"%tmpdir.name
    os.makedirs(confdir, mode=0o700)
    (status, out, err)=util.exec_sync([prog_path, "--root", confdir, "init"])
    if status!=0:
        raise Exception("Could not initialize empty global configuration structure: %s"%err)

    # copy repo configurations associated to the specified domain configurations
    ref_ts=0
    ref_rconf=None
    ref_arname=None
    for duid in domain_confs:
        dconf=gconf.get_domain_conf(duid)
        rconf=gconf.get_repo_conf(dconf.repo_id)
        (ts, lastarname)=rconf.get_latest_archive()
        if lastarname is None:
            raise Exception("Domain '%s' has no published version"%duid)
        util.print_event(f"Preparing to use domain configuration {_format_conf_oneline(rconf)}")
        if ref_ts<ts:
            ref_ts=ts
            ref_rconf=rconf
            ref_arname=lastarname
        util.write_data_to_file(json.dumps(rconf.export(new_path=rconf.id), indent=4),
                                 "%s/repo-configurations/%s.json"%(confdir, rconf.id))

    # use the most recent published domain configuration to extract global configuration elements
    if ref_rconf is None:
        raise Exception("No useable domain")
    try:
        mp=ref_rconf.mount(ref_arname)
        shutil.copyfile("%s/inseca.json"%mp, "%s/inseca.json"%confdir)
        if os.path.exists("%s/proxy.pac"%mp):
            shutil.copyfile("%s/proxy.pac"%mp, "%s/proxy.pac"%confdir)
        for fname in os.listdir("%s/storage-credentials"%mp):
            shutil.copyfile("%s/storage-credentials/%s"%(mp, fname), "%s/storage-credentials/%s"%(confdir, fname))
    finally:
        ref_rconf.umount(ref_arname)

    # include PRIVDATA's private key, if any
    if bconf and bconf.privdata_privkey:
        if not bconf.status.valid:
            raise Exception(f"Configuration {bconf.id} is invalid")
        credsdir="%s/credentials"%tmpdir.name
        os.makedirs(credsdir, mode=0o700)
        shutil.copyfile(bconf.privdata_privkey, "%s/privdata-ekey.priv"%credsdir)

    # create TAR archive
    tmpfile=tempfile.NamedTemporaryFile()
    tar=tarfile.open(tmpfile.name, mode="w:xz")
    for entry in os.listdir(tmpdir.name):
        tar.add("%s/%s"%(tmpdir.name, entry), arcname=entry, recursive=True)
    tar.close()
    return tmpfile

def _generate_admin_iso_file(iso_file, new_iso_file, extra_conf_file):
    """Customize the specified ISO file, and include the extra config file."""
    if not os.path.exists(iso_file):
        raise Exception("ISO file '%s' does not exist"%iso_file)

    try:
        # copy ISO file to a new TMP file
        util.print_event("Making a copy of the live Linux ISO file")
        shutil.copyfile(iso_file, new_iso_file)

        # compute the EFI's partition offset in the ISO
        (status, out, err)=util.exec_sync(["/sbin/fdisk", "-l", new_iso_file])
        if status!=0:
            raise Exception("Could not determine the structure of the ISO image")
        offset=0
        for line in out.splitlines():
            if "EFI" in line:
                parts=line.split()
                offset=int(parts[1])*512
        if offset==0:
            raise Exception("Could not identfy the EFI partition's offset in the ISO image")

        # create extra file to store the extra config file data
        util.print_event("Preparing zone to store the configuration")
        extra=tempfile.NamedTemporaryFile()
        f=open(extra.name, "a")
        f.truncate(1*1024*1024) # force size to 1Mb
        f.close()
        (status, out, err)=util.exec_sync(["/sbin/mkfs.ext4", extra.name]) 

        # mount extra file and copy the extra config into it
        extra_mp=tempfile.TemporaryDirectory()
        extra_mounted=False
        try:
            (status, out, err)=util.exec_sync(["sudo", "mount", "-o", "loop,rw", extra.name, extra_mp.name])
            if status!=0:
                raise Exception("Could not mount extra data: %s"%err)
            extra_mounted=True
            (status, out, err)=util.exec_sync(["sudo", "cp", "-a", extra_conf_file, "%s/config.txz.enc"%extra_mp.name])
            if status!=0:
                raise Exception("Could not copy extra data: %s"%err)
        finally:
            if extra_mounted:
                (status, out, err)=util.exec_sync(["sudo", "umount", extra_mp.name])

        # mount the EFI partition within the ISO image and indicate offset to the extra file
        efi_mp=tempfile.TemporaryDirectory()
        efi_mounted=False
        try:
            (status, out, err)=util.exec_sync(["sudo", "mount", "-o", "loop,rw,offset=%d,uid=%d"%(offset, os.getuid()),
                                               new_iso_file, efi_mp.name])
            if status!=0:
                raise Exception("Could not mount EFI partition in ISO file: %s"%err)
            efi_mounted=True
            util.write_data_to_file("%d"%os.path.getsize(iso_file), "%s/key-offset"%efi_mp.name)
        finally:
            if efi_mounted:
                (status, out, err)=util.exec_sync(["sudo", "umount", efi_mp.name])

        # concatenate extra file to the ISO
        util.print_event("Finalizing the new 'ISO' file")
        r=open(extra.name, "rb")
        w=open(new_iso_file, "ab")
        w.write(r.read())
        r=None
        w=None

        return new_iso_file
    except Exception as e:
        # remove copy if ISO file
        try:
            os.remove(new_iso_file)
        except Exception:
            pass
        raise e

def gen_admin_iso(args):
    if len(args.domains)==0:
        raise Exception("At least one domain configuration must be specified")
    if args.verbose:
        util.print_events=True
    iso_img_file=None
    bconf=None
    if args.build!="-":
        gconf=confs.GlobalConfiguration()
        bconf=gconf.get_build_conf(args.build)
        if bconf.build_type!=confs.BuildType.ADMIN:
            raise Exception(_("The build config is not an ADMIN build"))
        builder=LiveBuilder.Builder(args.build)
        iso_img_file=builder.image_file
        if not os.path.exists(iso_img_file):
            raise Exception("Can't generate admin image: the live Linux ISO image is not present")
    
    conf_tar=_prepare_config_data(args.domains, bconf)

    if iso_img_file is None:
        cfile="_config.txz"
        shutil.copyfile(conf_tar.name, cfile)
        print("Generated config file: %s"%cfile)
    else:
        # determine random password
        password=cgen.generate_password(12)
        print("Password for generated file is: %s"%password)

        # encrypt config data
        encobj=CryptoPass.CryptoPassword(password)
        econf_tar=encobj.encrypt(util.load_file_contents(conf_tar.name, binary=True), return_tmpobj=True)

        # generate new ISO
        new_iso_file="%s.new"%iso_img_file
        _generate_admin_iso_file(iso_img_file, new_iso_file, econf_tar.name)
        print("Generated new file: %s"%new_iso_file)

def _get_protected_data(dev, dkey):
    try:
        dev.define_a_decryptor(dkey)
        return dev.get_protected_data()
    except:
        raise Exception("Could not decrypt protected data (wrong decryption key?)")

def _dev_verify(dev, decrypt_key=None):
    gconf=confs.GlobalConfiguration()
    udata=dev.get_unprotected_data()

    dkey=decrypt_key # decrypt password
    if "confid" not in udata:
        raise Exception("Not an INSECA device (no 'confid' attribute)")

    confid=udata["confid"]
    conf=gconf.get_install_conf(confid, exception_if_not_found=False)
    if not conf:
        conf=gconf.get_format_conf(confid, exception_if_not_found=False)
    if conf:
        if dkey is None:
            dkey=conf.password_rescue
        pubkey=conf.devicemeta_pubkey
        if os.path.exists(pubkey):
            # identify how verification will be done
            (status, out, err)=util.exec_sync(["openssl", "x509", "-subject", "-noout", "-in", pubkey])
            if status==0:
                how={"type": "certificate", "cert-file": pubkey}
            else:
                how={"type": "key", "public-key-file": pubkey}
            # NB: for now, all the device's signature is performed using a key, no password
            #     how={"type": "password", "password": pubkey}

            # try to identify a signature ID
            verified=False
            for sid in dev.get_signature_ids():
                verifier={sid: how}
                try:
                    dev.verify(verifier)
                    udata=dev.get_unprotected_data()
                    verified=True
                    break
                except Exception:
                    pass
            if not verified:
                raise Exception("Altered device or wrong verification key in configuration")
    return (dkey, udata)

def dev_ident(args):
    # 1st pass to read the meta data
    if args.devfile is None:
        args.devfile=_get_single_useable_device()
    gconf=confs.GlobalConfiguration()
    dev=Device.Device(args.devfile)
    infos={}

    # try to verify the device
    verif_error=None
    dkey=None
    try:
        (dkey, udata)=_dev_verify(dev, args.decrypt_key)
        infos["unprotected"]=udata
    except adata.InvalidDevice as e:
        raise e
    except Exception as e:
        infos["verification-error"]=str(e)

    if args.verbose:
        # decrypt protected data if key is provided
        if args.protected and dkey is not None:
            pdata=_get_protected_data(dev, dkey)
            if pdata is not None:
                infos["protected"]=pdata

        # extra infos
        infos["hardware-id"]=dev.get_hardware_id()
        infos["dev-format"]=dev.get_partitions_layout()

    print("%s"%json.dumps(infos, indent=4))

def _dev_mount(dev, partition_id, decrypt_key=None, mountpoint=None):
    gconf=confs.GlobalConfiguration()
    udata=dev.get_unprotected_data()
    if "confid" not in udata:
        raise Exception("Not an INSECA device (no 'confid' attribute)")
    confid=udata["confid"]
    if decrypt_key is None:
        conf=gconf.get_install_conf(confid, exception_if_not_found=False)
        if not conf:
            conf=gconf.get_format_conf(confid, exception_if_not_found=False)
        if conf:
            decrypt_key=conf.password_rescue
    _get_protected_data(dev, decrypt_key)
    return dev.mount(partition_id, mountpoint, auto_umount=True if mountpoint is None else False)

def dev_mount(args):
    if args.devfile is None:
        args.devfile=_get_single_useable_device()
    dev=Device.Device(args.devfile)
    _dev_mount(dev, args.partition_id, args.decrypt_key, args.mountpoint)

def dev_umount(args):
    if args.devfile is None:
        args.devfile=_get_single_useable_device()
    dev=Device.Device(args.devfile)
    if args.partition_id!="-":
        dev.umount(args.partition_id)
    else:
        Device.umount_all_partitions(args.devfile)

def dev_wipe(args):
    if not args.devfile.startswith("/dev/"):
        raise Exception("Invalid device specification")
    if not args.confirm:
        c=input("Confirm wipe of '%s' (enter YES):"%args.devfile)
        if c!="YES":
            print("Cancelled")
            return
    if args.verbose:
        util.print_events=True
    dev=Device.Device(args.devfile)
    dev.wipe(only_metadata=args.metadata_only)

def _vm_stop(vm_name):
    args=["virsh", "-q", "list", "--all"]
    (status, out, err)=util.exec_sync(args)
    if status!=0:
        raise Exception("Could not list declared VM: %s"%err)
    for line in out.splitlines():
        if vm_name in line:
            args=["virsh", "destroy", vm_name]
            (status, out, err)=util.exec_sync(args)
            args=["virsh", "undefine", vm_name, "--nvram"]
            (status, out, err)=util.exec_sync(args)
            break

def dev_run_in_vm(args):
    if args.devfile is None:
        args.devfile=_get_single_useable_device()
    import namesgenerator
    vm_name=namesgenerator.get_random_name()
    _vm_stop(vm_name)
    if not args.devfile.startswith("/dev/"):
        # make sure the VM image is in a place suitable for apparmor
        pass
    # umount all partitions of @target
    Device.umount_all_partitions(args.devfile)

    mem=3072
    if args.mem:
        mem=int(args.mem)

    runargs=["virt-install", "--virt-type", "kvm", "--name", vm_name, "--memory", str(mem), "--import",
          "--disk", "%s,bus=virtio"%args.devfile, "--os-variant", "debian10", "--graphics", "spice", "--video", "qxl",
          "--tpm", "backend.type=emulator,backend.version=2.0,model=tpm-tis",
          "--channel", "spicevmc", "--network", "default"]
    if not args.bios:
        runargs+=["--boot", "uefi"]
    (status, out, err)=util.exec_sync(runargs)
    if status!=0:
        raise Exception("Could not start VM '%s': %s"%(vm_name, err))
    # closing the window => terminate the VM
    _vm_stop(vm_name)

def _get_and_validate_password(args):
    password=None
    if args.passenv:
        if args.passenv in os.environ:
            password=args.passenv
        else:
            raise Exception("Environment variable '%s' does not exist"%args.passenv)
    if args.password:
        password=args.password
    if password=="-":
        import getpass
        pw1=getpass.getpass(_("New password: "))
        pw2=getpass.getpass(_("Confirmation: "))
        if pw1!=pw2:
            raise Exception(_("Passwords mismatch"))
        password=pw1
    cgen.validate_password(password)
    return password

def _get_blob0(dev):
    gconf=confs.GlobalConfiguration()
    udata=dev.get_unprotected_data()
    if "confid" not in udata:
        raise Exception("Not an INSECA device (no 'confid' attribute)")
    confid=udata["confid"]
    conf=gconf.get_install_conf(confid, exception_if_not_found=False)
    if not conf:
        conf=gconf.get_format_conf(confid, exception_if_not_found=False)
    if conf:
        dkey=conf.password_rescue
    pdata=_get_protected_data(dev, dkey)
    try:
        return pdata["blob0"]
    except Exception:
        raise Exception("Invalid device's metadata")

def dev_users(args):
    """List all users declared in a device"""
    dev=Device.Device(args.devfile)
    mp_dummy=dev.mount(Live.partid_dummy)
    users=Live.get_users(mp_dummy)
    for user in users:
        print("%s"%user)

def dev_user_add(args):
    """Add a user to a device"""
    # get and validate password
    password=_get_and_validate_password(args)

    # get blob0
    dev=Device.Device(args.devfile)
    blob0=_get_blob0(dev)

    # user name
    mp_dummy=dev.mount(Live.partid_dummy)
    username=args.user.strip()
    if username in Live.get_users(mp_dummy):
        raise Exception("User '%s' already exists"%username)

    # declare user
    Live.declare_user(mp_dummy, username, password, blob0)

def dev_user_del(args):
    """Remove a user from a device"""
    # get blob0
    dev=Device.Device(args.devfile)
    blob0=_get_blob0(dev)

    # user name
    mp_dummy=dev.mount(Live.partid_dummy)
    username=args.user.strip()
    if username not in Live.get_users(mp_dummy):
        raise Exception("User '%s' does not exist")

    # delete user
    mp_internal=dev.mount(Live.partid_internal)
    Live.delete_user(mp_dummy, username, mp_internal)

def dev_user_password(args):
    """Reset the user's password"""
    # get and validate password
    password=_get_and_validate_password(args)

    # get blob0
    dev=Device.Device(args.devfile)
    blob0=_get_blob0(dev)

    # user name
    mp_dummy=dev.mount(Live.partid_dummy)
    users=Live.get_users(mp_dummy)
    if args.user not in users:
        raise Exception("Invalid user '%s'"%args.user)

    # actually reset the password
    Live.reset_user_password(mp_dummy, args.user, password, blob0)


def gen_keypair(args):
    prefix=args.prefix
    dirname=os.path.dirname(prefix)
    if dirname:
        os.makedirs(dirname, exist_ok=True)
    (key_priv, key_pub)=x509.gen_rsa_key_pair()
    key_priv.copy_to(prefix+".priv")
    key_pub.copy_to(prefix+".pub")
    os.chmod(prefix+".priv", 0o600)


class CheckEnviron(Live.Environ):
    """Dummy environ to satisfy BootProcessWKS"""
    def __init__(self, dev):
        self._dev=dev

    @property
    def logged(self):
        return False

    @property
    def unlocked(self):
        return False

def _log_compare(expected_log, computed_log):
    """Returns a list of differences between the expected log and the computed one"""
    diffs=[]
    try:
        for (edata, cdata) in zip(expected_log, computed_log, strict=True):
            if edata!=cdata:
                if type(edata)!=type(cdata):
                    diffs.append("Error: type difference between '%s' and '%s"%(edata, cdata))
                elif isinstance(edata, str):
                    diffs.append("Expected '%s', got '%s'"%(edata, cdata))
                elif isinstance(edata, dict):
                    d2=_log_compare(edata, cdata)
                    diffs+=d2
    except ValueError:
        diffs.append("Incomplete or too long integrity log")
    except Exception as e:
        diffs.append("Error: %s"%str(e))
    return diffs

def dev_check(args):
    if args.devfile is None:
        args.devfile=_get_single_useable_device()
    try:
        dev=Device.Device(args.devfile)
        _dev_verify(dev)

        dummy_env=CheckEnviron(dev)
        bp=Live.BootProcessWKS(dummy_env, dev)
        blob0=_get_blob0(dev)
    except Exception as e:
        print("Error: could not decrypt blob0 (%s)"%err)

    try:
        bp.check_integrity(blob0)
        print("Ok")
    except Exception as e:
        (err, log)=e.args
        print("Error: %s"%err)
        if log:
            mp=_dev_mount(dev, "internal")
            oklog=json.load(open("%s/resources/integrity-fingerprint-log.json"%mp, "r"))
            diffs=_log_compare(oklog, log)
            if diffs:
                for item in diffs:
                    print(item)
            else:
                print("Integrity logs is Ok")
        sys.exit(1)

#
# Main
#
args = parser.parse_args()

if args.root is not None:
    os.environ["INSECA_ROOT"]=args.root
if args.repos_dir is not None:
    os.environ["INSECA_DEFAULT_REPOS_DIR"]=args.repos_dir
if args.components_dir is not None:
    os.environ["INSECA_EXTRA_COMPONENTS"]=args.components_dir
if args.http_proxy is not None:
    if args.http_proxy=="none":
        os.environ["INSECA_NO_HTTP_PROXY"]="1"
    else:
        os.environ["http_proxy"]=args.http_proxy
        os.environ["https_proxy"]=args.http_proxy
if args.cache_dir is not None:
    os.environ["INSECA_CACHE_DIR"]=args.cache_dir

try:
    if args.cmde is None:
        print("%s"%parser.format_help())
    else:
        map={
            "init": init,
            "status": show_status,
            "configs": list_configs,
            "config-infos": config_infos,
            "config-create": config_create,
            "config-clone": config_clone,
            "config-remove": config_remove,
            "config-publish": config_publish,
            "repo-ls": repo_ls,
            "repo-prune": repo_prune,
            "userdata-import": userdata_import,
            "userdata-add": userdata_add,
            "userdata-del": userdata_del,
            "build": build,
            "dev-install": dev_install,
            "gen-params": gen_params,
            "sync-push": sync_push,
            "sync-pull": sync_pull,
            "gen-admin-iso": gen_admin_iso,
            "devices": devices,
            "dev-update-linux": dev_update_linux,
            "dev-format": dev_format,
            "dev-ident": dev_ident,
            "dev-mount": dev_mount,
            "dev-umount": dev_umount,
            "dev-wipe": dev_wipe,
            "dev-copy": dev_copy,
            "dev-run-in-vm": dev_run_in_vm,
            "dev-users": dev_users,
            "dev-user-add": dev_user_add,
            "dev-user-del": dev_user_del,
            "dev-user-password": dev_user_password,
            "gen-keypair": gen_keypair,
            "dev-check": dev_check
        }
        if args.cmde in map:
            if args.cmde in root_required_commands and os.getuid()!=0:
                # execute the same command with sudo
                print(_("This command needs root privileges"))
                args=sys.argv[1:]
                options={
                    "--root": os.environ["INSECA_ROOT"]
                }
                if "INSECA_EXTRA_COMPONENTS" in os.environ:
                    options["--components-dir"]=os.environ["INSECA_EXTRA_COMPONENTS"]
                if "http_proxy" in os.environ:
                    options["--http-proxy"]=os.environ["http_proxy"]
                for option in options:
                    toadd=True
                    if not option in args:
                        for arg in args:
                            if arg.startswith("%s="%option):
                                toadd=False
                                break
                    else:
                        toadd=False
                    if toadd:
                        args=[option, options[option]]+args
                args=["sudo", prog_path]+args
                try:
                    p=util.exec_async(args)
                    p.wait()
                    sys.exit(p.returncode)
                except KeyboardInterrupt:
                    print("Cancelled")
                    sys.exit(0)
            map[args.cmde](args)
        else:
            print("%s"%parser.format_help())
except Exception as e:
    print("Error: %s"%str(e), file=sys.stderr)
    sys.exit(1)