# This file is part of INSECA.
#
#    Copyright (C) 2020-2023 INSECA authors
#
#    INSECA is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    INSECA is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with INSECA.  If not, see <https://www.gnu.org/licenses/>

import json
import os
import CryptoGen as crypto
import Utils as util
import FingerprintHash as fphash

# Gettext stuff
import gettext
lib_dir=os.path.dirname(__file__)
gettext.bindtextdomain("inseca", lib_dir+"/locales")
gettext.textdomain("inseca")
_ = gettext.gettext

_size_len=20 # encrypted data length is max 20 bytes

def _replace_internal_references(data, layout):
    if isinstance(data, str):
        if data[0]=="@":
            (part_id, what)=data[1:].split("/")
            for partdata in layout["partitions"]:
                if "id" in partdata and partdata["id"]==part_id:
                    if what not in partdata:
                        raise Exception(_("Could not find reference '%s'")%data)
                    return partdata[what]
            raise Exception(_("Could not find reference '%s'")%data)
        else:
            return data
    elif isinstance(data, dict):
        ndata={}
        for key in data:
            if data[key]:
                ndata[key]=_replace_internal_references(data[key], layout)
            else:
                nvalue=_replace_internal_references(key, layout)
                ndata[key]=nvalue
        return ndata
    elif isinstance(data, list):
        ndata=[]
        for key in data:
            ndata+=[_replace_internal_references(key, layout)]
        return ndata
    return data

class InvalidDevice(Exception):
    pass

class AppendedData:
    """Manage some appended data.
    2 modes:
    - create security if @specs and @layout are specified
    - read drom the device if not

    In creation mode:
    - the specs are generated by a SpecBuilder.Builder object
    - the layout is generated by Device.Device.format()
    """
    def __init__(self, devfile, specs=None, layout=None):
        self._devfile=devfile
        if specs and not layout or layout and not specs:
            raise Exception(_("In creation mode, both specs and layout are expected"))
        self._specs=specs
        self._layout=layout

        if self._layout:
            if devfile!=layout["device"]["devfile"]:
                layout=layout["device"]["devfile"]
                raise Exception(_(f"Device file mismatch: '{devfile}' specified and '{layout}' in layout"))
            self._disktype=layout["device"]["type"]
        else:
            self._disktype=util.get_device_label_type(self._devfile)

        # data manipulated by sub classed objects
        self._data=None

    @property
    def devfile(self):
        return self._devfile

    def _get_end_offset(self):
        """Returns the last offset where the information will be stored"""
        return 0

    def _get_length_offset_at(self, end_offset):
        """Return the offset (from the end of the device backward) to get the length of the section to read,
        of to write that section's length, using @end_offset as the reference."""
        if self._disktype==util.LabelType.DOS:
            offset=end_offset+_size_len
        elif self._disktype==util.LabelType.GPT or self._disktype==util.LabelType.HYBRID:
            offset=end_offset+_size_len+512*34 # before secondary GPT header
        else:
            raise Exception(_("Unknown partitioning type '%s'")%self._disktype)
        return offset

    def _get_start_offset(self, data_length):
        """Return the offset from the end of the device to start reading section data or write it"""
        import Device
        length_offset=self._get_length_offset_at(self._get_end_offset())
        offset=length_offset+data_length
        reserved=Device.mb_to_bytes(Device.end_reserved_space)
        if offset>reserved:
            raise Exception(_(f"Not enough reserved space on device (got {offset} out of {reserved} reserved)"))
        return offset

    def write_to_device(self):
        """Write data to the device"""
        if not self._data:
            raise Exception(_("Actual metadata has not yet been created or read from the device"))

        # encrypt data
        jdata=json.dumps(self._data, sort_keys=True).encode()
        jlen=len(jdata)
        ldata=_encode_size(jlen)
        if len(ldata)>_size_len:
            raise Exception(_("Not enough reserved space for metadata's length"))

        # determine writing offset (starting from the last byte of the device, going backward)
        offset=self._get_start_offset(jlen)
        if util.debug:
            print("Writing @%d:"%offset)
            print("   data (len=%d) to offet %d included "%(jlen, offset-jlen))
            print("   data'length (%s) to offet %d included "%(ldata, offset-jlen-_size_len))

        # actual write
        fd=open(self._devfile, "rb+")
        fd.seek(-offset, 2)
        fd.write(jdata)
        fd.write(ldata)
        fd.close()

    def read_data_length(self, end_offset=0):
        # read data's length
        offset=self._get_length_offset_at(end_offset)
        fd=open(self._devfile, "rb+")
        fd.seek(-offset, 2)
        ldata=fd.read(_size_len)
        return _decode_size(ldata)

    def read_from_device(self):
        # read data's length
        jlen=self.read_data_length(self._get_end_offset())
        offset=self._get_start_offset(jlen)

        # read data
        fd=open(self._devfile, "rb+")
        fd.seek(-offset, 2)
        jdata=fd.read(jlen)
        fd.close()

        # decode read data
        try:
            self._data=json.loads(jdata.decode())
        except:
            raise InvalidDevice(_("Absent or invalid device signature"))

#
# Meta Data
#
class MetaData(AppendedData):
    """Manage metadata"""
    def __init__(self, devfile, specs=None, layout=None):
        AppendedData.__init__(self, devfile, specs, layout)
        self._data=None
        if self._layout:
            self._create()

    def _create(self):
        """Create the metadata from the specifications and the data generated by the Device.Device.format() function"""
        if not self._specs:
            raise Exception(_("Can't create metadata in non creation mode"))

        # create objects from ACL specs
        dec_objects=crypto.create_crypto_objects_list(self._specs["decryptors"])

        # create protected data
        protected=_replace_internal_references(self._specs["protected"], self._layout)
        eprotected={}
        for name in protected:
            dec_obj=dec_objects[name]
            edata=dec_obj.encrypt(protected[name])
            eprotected[name]=edata

        # create verification data
        verif={
            "type": self._disktype.value,
            "table-hash": self._layout["device"]["analysed-table-hash"],
            "partitions": []
        }
        for part in self._layout["partitions"]:
            vpart={
                "filesystem": part["filesystem"],
                "immutable": part["immutable"],
                "label": part["label"],
                "number": part["number"],
                "sector-start": part["sector-start"],
                "sector-end": part["sector-end"],
                "size-bytes": part["size-bytes"],
                "type": part["type"],
                "devfile-ext": part["devfile-ext"],
            }
            for extra in ("id", "encryption"):
                if extra in part:
                    vpart[extra]=part[extra]
            if "analysed-hash" in part:
                vpart["hash"]=part["analysed-hash"]
            if "analysed-files-hash" in part:
                vpart["files-hash"]=part["analysed-files-hash"]
            verif["partitions"]+=[vpart]

        # create signed data
        signeddata={
            "hw-id": self._layout["device"]["hw-id"],
            "verif": verif,
            "unprotected": _replace_internal_references(self._specs["unprotected"], self._layout),
            "protected": eprotected
        }

        # compute signature
        signatures={}
        sign_objects=crypto.create_crypto_objects_list(self._specs["signatures"])
        for item in self._specs["signatures"]:
            sign_obj=sign_objects[item]
            signed=sign_obj.sign(signeddata)
            signatures[item]=signed

        self._data={
            "signeddata": signeddata,
            "signatures": signatures
        }

    def get_signatures(self):
        if not self._data:
            raise Exception("Actual metadata has not yet been created or read from the device")
        return self._data["signatures"]

    def verify(self, verifiers):
        """Verify the metadata:
        - metadata's signature
        - device ID's association with metadata
        - verify the partitioning scheme has not been changed
        - validity of table of partition's signature
        - verify that non encrypted filesystems have not changed
        - validity of immutable partition's signatures

        NB: the @verifiers is a dictionary of verififcation methods indexed by a name, which must be
            the same as the one specified in the metadata
        """
        if not self._data:
            raise Exception(_("Actual metadata has been read from the device"))
        if not verifiers:
            raise Exception(_("No metadata verifiers provided"))

        if util.debug:
            print("METADATA to validate:\n%s"%json.dumps(self._data, indent=4, sort_keys=True))
        sd=self._data["signeddata"]

        # verify signature
        signature_verified=False
        dec_objects=crypto.create_crypto_objects_list(verifiers)
        for objid in self._data["signatures"]:
            if objid in dec_objects:
                obj=dec_objects[objid]
                obj.verify(sd, self._data["signatures"][objid])
                signature_verified=True
        if not signature_verified:
            raise Exception(_("No matching signature verifer: metadata's signature could not be verified"))

        hwdata=sd["hw-id"]
        verifdata=sd["verif"]

        # device association
        if False: # not used because different linux versions return different values
            model=util.get_device_model(self._devfile)
            if model!=hwdata["model"]:
                raise Exception(_("H/W model mismatch: wrong device"))

        if not self.devfile.startswith("/dev/vda"):
            # don't wheck for serial numbers in VMs, information does not appear to be reliable.
            serial=util.get_device_serial(self._devfile)
            if serial!=hwdata["serial"]:
                raise Exception(_("Serial numbers mismatch: wrong device"))

        (disksize, sectorsize)=util.get_disk_sizes(self._devfile)
        if disksize!=hwdata["size-bytes"]:
            raise Exception(_("Device size mismatch: wrong device"))
    
        # partitions table
        if self._disktype.value!=verifdata["type"]:
            etype=verifdata["type"]
            gtype=self._disktype.value
            raise Exception(_(f"Partition label scheme has been altered from '{etype}' to '{gtype}'"))

        fp=fphash.compute_partitions_table_hash(self._devfile, self._disktype)
        if fp!=verifdata["table-hash"]:
            raise Exception(_("Partition table has been altered"))

        # filesystem types & immutable partitions' data
        for partdata in verifdata["partitions"]:
            partfile=self._devfile+partdata["devfile-ext"]
            if "encryption" in partdata and partdata["encryption"]==None:
                (fstype, fslabel)=util.get_partition_infos(partfile)
                if fstype!=partdata["filesystem"]:
                    number=partdata["number"]
                    fs=partdata["filesystem"]
                    raise Exception(_(f"Filesystem for partition {number} has been modified from '{fs}' to '{fstype}'"))

            if "hash" in partdata:
                fp=fphash.compute_partition_hash(partfile)
                if fp!=partdata["hash"]:
                    raise Exception(_("Partition %d has been altered")%partdata["number"])
            if "files-hash" in partdata:
                fp=fphash.compute_files_hash(partfile)
                if fp!=partdata["files-hash"]:
                    raise Exception(_("Files in partition %d have changed")%partdata["number"])

    def get_data(self):
        if not self._data:
            raise Exception(_("Actual metadata has been read from the device"))
        return self._data["signeddata"]

#
# Security Data
#
class SecurityData(AppendedData):
    """Manage security data (ACL + signatures)"""
    def __init__(self, devfile, specs=None, layout=None):
        AppendedData.__init__(self, devfile, specs, layout)
        if self._specs:
            self._create()

    def _create(self):
        if not self._specs:
            raise Exception(_("Can't create security data in non creation mode"))
        data={
            "access": {},
            "signatures": {} # no extra signature yet
        }
        self._data=data

    def _get_end_offset(self):
        # offset takes into account the metadata (and the bytes to store its length) already existing
        meta_offset=self.read_data_length(0)+_size_len+1
        return meta_offset

def _encode_size(size):
    """Encode an integer as bytes"""
    string=b''
    while True:
        value=size % 100
        vh=int(value/10)
        vl=value%10
        v=vh*16+vl
        string=bytes([v])+string
        size=int(size / 100)
        if size==0:
            break
    string=bytes([0]*(_size_len-len(string)))+string
    return string

def _decode_size(data):
    """Reverse of _encode_size()"""
    size=0
    factor=1
    for c in data[::-1]:
        l=int(c & 15)
        size+=l*factor

        l=int(c>>4 & 15)
        size+=l*10*factor
        factor*=100
    return size
